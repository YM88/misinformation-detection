{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02- Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/cleaned_tweets.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = []\n",
    "for word in df.cleaned.str.split().to_list():\n",
    "    bow += word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_set = set(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9861"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bow_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [(tweet, cat) for tweet, cat in zip(df.cleaned, df.category.to_list())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets, cats = (zip(*texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [tweet.split()for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbow = Word2Vec(corpus, vector_size=300, min_count=1, epochs=10, seed=42)\n",
    "model_sg = Word2Vec(corpus, sg=1, vector_size=300, min_count=1, epochs=10, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_cbow = {word: model_cbow.wv[word] for word in bow_set}\n",
    "we_sg = {word: model_sg.wv[word] for word in bow_set}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9861, 9861)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(we_cbow), len(we_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meaner(word_embedding, tweets):\n",
    "    tweet_embedding = {}\n",
    "    for i, tweet in enumerate(tweets):\n",
    "        tweet_embedding[tweet] = np.mean(np.array([word_embedding[word] for word in tweets[i].split()]), axis=0)\n",
    "    return tweet_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_cbow = meaner(we_cbow, tweets)\n",
    "te_sg = meaner(we_sg, tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_cbow_df = pd.DataFrame(te_cbow).T.reset_index().rename(columns={'index':'tweet'})\n",
    "te_cbow_df['category'] = cats\n",
    "te_cbow_df['label'] = te_cbow_df.category.map({'unreliable':0, 'true':1})\n",
    "te_cbow_df = te_cbow_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "te_sg_df = pd.DataFrame(te_sg).T.reset_index().rename(columns={'index':'tweet'})\n",
    "te_sg_df['category'] = cats\n",
    "te_sg_df['label'] = te_sg_df.category.map({'unreliable':0, 'true':1})\n",
    "te_sg_df = te_sg_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(te_cbow_df, open(\"../data/te_cbow_df_training_unshared.pickle\", \"wb\"))\n",
    "pickle.dump(te_sg_df, open(\"../data/te_sg_df_training_unshared.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(we_cbow, open(\"../data/we_cbow_training_unshared.pickle\", \"wb\"))\n",
    "pickle.dump(we_sg, open(\"../data/we_sg_training_unshared.pickle\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "033bd3c1329338defdc4c98345d63580936211b5a58345c09a4ef95f2034f40b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
